name: Update LinkedIn Resume

on:
  # Run weekly on Sundays at 6 AM UTC
  schedule:
    - cron: '0 6 * * 0'
  
  # Allow manual triggering
  workflow_dispatch:
  
  # Run on pushes to main branch (for testing)
  push:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.11'

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write  # Required to push changes back to repository
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        playwright install chromium
        
    - name: Configure environment
      env:
        LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
        LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}
        LINKEDIN_TOTP_SECRET: ${{ secrets.LINKEDIN_TOTP_SECRET }}
      run: |
        echo "LINKEDIN_EMAIL=$LINKEDIN_EMAIL" >> $GITHUB_ENV
        echo "LINKEDIN_PASSWORD=$LINKEDIN_PASSWORD" >> $GITHUB_ENV
        echo "LINKEDIN_TOTP_SECRET=$LINKEDIN_TOTP_SECRET" >> $GITHUB_ENV
        
    - name: âš ï¸ COMPLIANCE WARNING âš ï¸
      run: |
        echo "=================== LINKEDIN ToS COMPLIANCE WARNING ==================="
        echo "This workflow scrapes LinkedIn data for personal resume generation only."
        echo "LinkedIn ToS prohibits storing/redistributing scraped profile content."
        echo "Only the user's OWN profile data should be processed."
        echo "Raw scraped data is immediately deleted after resume generation."
        echo "======================================================================"
        
    - name: Generate privacy-safe resume (ToS compliant)
      run: |
        # Set strict error handling and register cleanup trap
        set -e
        
        # Register EXIT trap to guarantee cleanup of raw data files
        cleanup() {
          echo "ðŸ—‘ï¸ Cleaning up raw LinkedIn data files for compliance..."
          rm -f linkedin_data.json linkedin_data_enhanced.json profile_data.json
          echo "âœ… Cleanup completed"
        }
        trap cleanup EXIT
        
        # Set CI environment flag to bypass interactive confirmation
        export LINKEDIN_CI_MODE=true
        
        # Try new CLI first, fallback to legacy if needed
        if python -c "import src.linkedin_resume_generator" 2>/dev/null; then
          echo "ðŸš€ Using new modular architecture"
          python main.py scrape --format both
        else
          echo "ðŸ“¦ Using legacy implementation"
          python run_legacy.py
        fi
        
        echo "ðŸ”’ Resume generation completed successfully"
      env:
        LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
        LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}
        LINKEDIN_TOTP_SECRET: ${{ secrets.LINKEDIN_TOTP_SECRET }}
        
    - name: Verify compliance - Ensure no raw data remains
      run: |
        if [ -f "linkedin_data.json" ] || [ -f "linkedin_data_enhanced.json" ]; then
          echo "âŒ COMPLIANCE VIOLATION: Raw LinkedIn data still exists!"
          rm -f linkedin_data.json linkedin_data_enhanced.json
          echo "ðŸ—‘ï¸ Emergency cleanup completed"
        else
          echo "âœ… Compliance verified: No raw LinkedIn data found"
        fi
        
    - name: Run automated compliance audit
      run: |
        # Run compliance audit and capture result
        if python3 compliance_auditor.py; then
          echo "âœ… Compliance audit passed with no issues"
        else
          audit_exit_code=$?
          echo "âš ï¸ Compliance audit completed with warnings (exit code: $audit_exit_code)"
          
          # Check if there are violations (critical failures) vs warnings (non-critical)
          latest_audit=$(ls -t compliance_audit_*.json 2>/dev/null | head -1 || echo "")
          if [ -n "$latest_audit" ] && [ -f "$latest_audit" ]; then
            violations=$(python3 -c "import json; f=open('$latest_audit'); data=json.load(f); print(len(data.get('violations', [])))" 2>/dev/null || echo "0")
            
            if [ "$violations" -gt 0 ]; then
              echo "âŒ CRITICAL: Compliance violations detected - failing workflow"
              exit 1
            else
              echo "âœ… No critical violations found - continuing workflow with warnings"
            fi
          else
            echo "âš ï¸ Could not verify audit results - continuing with caution"
          fi
        fi
        echo "ðŸ“‹ Compliance audit completed"
        
    - name: Check for resume changes only
      id: verify-changed-files
      run: |
        # Only check for resume files, not raw data
        if [ -n "$(git status --porcelain -- resume.md index.md)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
          echo "Resume files updated"
        else
          echo "changed=false" >> $GITHUB_OUTPUT
          echo "No resume changes detected"
        fi
        
    - name: Commit and push resume updates only
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add ONLY final resume files (not raw scraped data)
        git add resume.md index.md
        
        # Create commit with compliance note
        git commit -m "Update resume from own LinkedIn profile - $(date -u +"%Y-%m-%d %H:%M:%S UTC") [ToS Compliant]"
        
        # Push changes
        git push
        
    - name: Upload resume artifacts only (ToS compliant)
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: resume-files
        path: |
          resume.md
          index.md
        retention-days: 30
        
    - name: Deploy to GitHub Pages (if enabled)
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        echo "Resume updated and committed. If GitHub Pages is enabled, it will deploy automatically."
        echo "Visit your repository's Pages settings to enable GitHub Pages deployment from the main branch."